{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b47e03c-8369-48a0-842d-34c2aa9a37d4",
   "metadata": {},
   "source": [
    "# LLM Enhanced API testing  \n",
    "Perform security testing based on an OpenAPI spec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41323f2-4937-4204-98df-58fba54082e8",
   "metadata": {},
   "source": [
    "## 1 - Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3495d997-f708-490e-b1cf-761afa5b28d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output folder -  /m2-data/jupyterNotebooks/api/test_runs/vampi-20250101/\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Set up the environment\n",
    "\n",
    "TODO\n",
    "redo contents to streamline\n",
    "LLM help:\n",
    "use tags for registration, login, user related endpoints\n",
    "get required request params with examples \n",
    "     - deal with arguments like {username}\n",
    "     - generate example data based on spec\n",
    "         example : Pass 'Moby Dick\" to {book_title} \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def create_output_folder():\n",
    "    \"\"\"\n",
    "    Create a timestamped folder for the output files.\n",
    "    \"\"\"\n",
    "    # TODO - need to rethink this\n",
    "    # long version\n",
    "    # timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # this will create a daily folder\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "    folder_name = f\"{project_name}-{timestamp}/\"\n",
    "    output_folder = os.path.join(output_base_path, folder_name)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    return output_folder\n",
    "\n",
    "## File Paths\n",
    "# API spec path\n",
    "api_spec_path = \"/m2-data/jupyterNotebooks/api/spec/openapi3Vampi.yml\"\n",
    "# base output folder path\n",
    "output_base_path = \"/m2-data/jupyterNotebooks/api/test_runs/\"\n",
    "# Project name \n",
    "project_name = \"vampi\"\n",
    "# project_name = \"crapi\"\n",
    "\n",
    "#models\n",
    "# model_name = \"gemma2:9b\"\n",
    "# model_name = \"qwen2.5-coder:7b\"\n",
    "# model_name = \"llama3.1:latest\"  #7b\n",
    "model_name = \"llama3.2:3b\"\n",
    "# model_name = \"llama3.2:1b\"\n",
    "# model_name = \"tinyllama:latest\"\n",
    "\n",
    "# test data setup\n",
    "test_email_domain = \"test.com\"\n",
    "base_test_username = \"adb123\"\n",
    "\n",
    "# create a new folder for this run\n",
    "# this is the base path appended w/ the project name and a daily timestamp\n",
    "output_folder = create_output_folder()\n",
    "print(\"output folder - \", output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec917e3-f7f9-4505-86d8-7a7f71ef90cb",
   "metadata": {},
   "source": [
    "## 2 - Validate and parse the spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3813df16-c486-4d08-9f8a-db05c9675ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAPI spec validation successful.\n",
      "Parsed specification details saved to: /m2-data/jupyterNotebooks/api/test_runs/vampi-20250101/parsed_spec.json\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Open the API spec and parse it for endpoints\n",
    "input - API spec\n",
    "output - parsed_spec.json\n",
    "'''\n",
    "\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from openapi_spec_validator import validate_spec\n",
    "\n",
    "\n",
    "def validate_openapi_spec(file_path, output_folder):\n",
    "    \"\"\"\n",
    "    Validates the OpenAPI specification and attempts partial parsing on failure.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the OpenAPI specification file.\n",
    "        output_folder (str): Path to the output folder for logging.\n",
    "\n",
    "    Returns:\n",
    "        dict: The parsed OpenAPI specification (best effort), or an empty dict if parsing completely fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            if file_path.endswith('.json'):\n",
    "                spec = json.load(file)\n",
    "            elif file_path.endswith(('.yaml', '.yml')):\n",
    "                spec = yaml.safe_load(file)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format. Only JSON and YAML are allowed.\")\n",
    "\n",
    "        validate_spec(spec)\n",
    "        print(\"OpenAPI spec validation successful.\")\n",
    "        return spec\n",
    "\n",
    "    except (json.JSONDecodeError, yaml.YAMLError) as e:\n",
    "        error_message = f\"Failed to parse the specification file: {e}\"\n",
    "    except Exception as e:  # Generic handling for validation errors\n",
    "        error_message = f\"Validation error: {e}\"\n",
    "\n",
    "    # Log validation errors\n",
    "    log_file = os.path.join(output_folder, \"validation_errors.log\")\n",
    "    with open(log_file, 'w') as log:\n",
    "        log.write(error_message)\n",
    "    print(f\"Validation failed. Errors logged to: {log_file}\")\n",
    "\n",
    "    # Attempt to return partial spec if possible\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            if file_path.endswith('.json'):\n",
    "                return json.load(file)\n",
    "            elif file_path.endswith(('.yaml', '.yml')):\n",
    "                return yaml.safe_load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to perform partial parsing: {e}\")\n",
    "        return {}\n",
    "\n",
    "def parse_spec_details(spec):\n",
    "    \"\"\"\n",
    "    Parses the OpenAPI specification to extract servers, endpoints, and additional metadata.\n",
    "\n",
    "    Args:\n",
    "        spec (dict): The OpenAPI specification.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing servers, endpoints, and useful metadata.\n",
    "    \"\"\"\n",
    "    endpoints = []\n",
    "    servers = spec.get('servers', [])\n",
    "    info = spec.get('info', {})\n",
    "    tags = spec.get('tags', [])\n",
    "    security = spec.get('security', [])\n",
    "    external_docs = spec.get('externalDocs', {})\n",
    "\n",
    "    for path, methods in spec.get('paths', {}).items():\n",
    "        for method, details in methods.items():\n",
    "            endpoint_info = {\n",
    "                \"path\": path,\n",
    "                \"method\": method.upper(),\n",
    "                \"parameters\": details.get(\"parameters\", []),\n",
    "                \"requestBody\": details.get(\"requestBody\", {}).get(\"content\", {}),\n",
    "                \"responses\": details.get(\"responses\", {})\n",
    "            }\n",
    "            endpoints.append(endpoint_info)\n",
    "\n",
    "    return {\n",
    "        \"servers\": servers,\n",
    "        \"info\": info,\n",
    "        \"tags\": tags,\n",
    "        \"security\": security,\n",
    "        \"externalDocs\": external_docs,\n",
    "        \"endpoints\": endpoints\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to validate and parse the OpenAPI spec, saving output to JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate the spec\n",
    "    spec = validate_openapi_spec(api_spec_path, output_folder)\n",
    "    if not spec:\n",
    "        print(\"Failed to validate or parse the OpenAPI spec. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Parse spec details\n",
    "    parsed_data = parse_spec_details(spec)\n",
    "\n",
    "    # Save parsed data to a JSON file\n",
    "    output_file = os.path.join(output_folder, \"parsed_spec.json\")\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(parsed_data, file, indent=4)\n",
    "\n",
    "    print(f\"Parsed specification details saved to: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16dd29-29b8-4e7d-ae2c-3dd49ad57d48",
   "metadata": {},
   "source": [
    "## 3 - Health Checks - LLM Assisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376d98d3-4b6c-4659-83f7-1a9c17f7b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with the models (or not)\n",
    "# model_name = \"gemma2:9b\"\n",
    "# model_name = \"qwen2.5-coder:7b\"\n",
    "# model_name = \"llama3.1:latest\"  #7b\n",
    "# model_name = \"llama3.2:3b\"\n",
    "# model_name = \"llama3.2:1b\"\n",
    "# model_name = \"tinyllama:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95cbbea1-e7cb-455e-bd4b-e14a1375a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model -  llama3.2:3b\n",
      "sending payload to LLM...\n",
      "JSON parsing error: Expecting value: line 1 column 2 (char 1)\n",
      "Health endpoints saved to: /m2-data/jupyterNotebooks/api/test_runs/vampi-20250101/endpoints_health.json\n",
      "Top 3 Heartbeat Endpoint Candidates:\n",
      "1. Path: /createdb, Method: GET\n",
      "2. Path: /, Method: GET\n",
      "3. Path: /users/v1, Method: GET\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Use LLM to determine endpoints that can serve as a health or heartbeat type check\n",
    "Looks for empty requests with 200 responses\n",
    "input - parsed_spec.json\n",
    "output - endpoints_health.json\n",
    "\n",
    "TODO \n",
    "fix JSON parsing error: Expecting value: line 1 column 2 (char 1) message\n",
    "Set priority/disable??\n",
    "    createdb works but resets the database so not a good option\n",
    "\n",
    "'''\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "parsed_spec_path = f\"{output_folder}parsed_spec.json\"\n",
    "health_endpoints_path = f\"{output_folder}endpoints_health.json\"\n",
    "model_url = \"http://localhost:11434/api/generate\"  # Ollama API endpoint\n",
    "\n",
    "def find_candidate_endpoints(parsed_spec):\n",
    "    \"\"\"\n",
    "    Identify candidate heartbeat endpoints based on the criteria.\n",
    "\n",
    "    Args:\n",
    "        parsed_spec (dict): The parsed OpenAPI spec JSON content.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of candidate endpoints with 200 OK responses and no parameters.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    endpoints = parsed_spec.get(\"endpoints\", [])\n",
    "    \n",
    "    for endpoint in endpoints:\n",
    "        # Check for 200 OK response\n",
    "        responses = endpoint.get(\"responses\", {})\n",
    "        if \"200\" in responses:\n",
    "            # Check for no parameters or requestBody\n",
    "            if not endpoint.get(\"parameters\") and not endpoint.get(\"requestBody\"):\n",
    "                candidates.append(endpoint)\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def query_model_for_ranking(candidates):\n",
    "    \"\"\"\n",
    "    Query the model to rank or refine candidate heartbeat endpoints.\n",
    "\n",
    "    Args:\n",
    "        candidates (list): A list of candidate endpoints.\n",
    "\n",
    "    Returns:\n",
    "        list: Ranked or refined list of heartbeat endpoints.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are analyzing API endpoints. Based on the following candidates, rank the endpoints \"\n",
    "        \"most likely to be a heartbeat endpoint, which typically returns 200 OK with no parameters. \"\n",
    "        \"Return the top 3 most probable candidates as a JSON array.\\n\\n\"\n",
    "        f\"Candidates:\\n{json.dumps(candidates, indent=2)}\\n\\n\"\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    print(\"model - \", model_name)\n",
    "    print(\"sending payload to LLM...\")\n",
    "    # print(\"prompt : \", prompt)\n",
    "\n",
    "    try:\n",
    "        # Stream the response for incremental output\n",
    "        response = requests.post(model_url, json=payload, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Process the streamed response incrementally\n",
    "        result = \"\"\n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                try:\n",
    "                    # Decode each line and append to result\n",
    "                    result += chunk.decode('utf-8')\n",
    "                except Exception as decode_error:\n",
    "                    print(f\"Error decoding chunk: {decode_error}\")\n",
    "\n",
    "        # Attempt to extract JSON from the response\n",
    "        try:\n",
    "            # Locate and parse the JSON part of the response\n",
    "            start_idx = result.find(\"[\")  # Assuming JSON array starts with [\n",
    "            end_idx = result.rfind(\"]\") + 1  # Assuming JSON array ends with ]\n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                ranked_candidates = json.loads(result[start_idx:end_idx])\n",
    "            else:\n",
    "                raise ValueError(\"Could not locate JSON array in model response.\")\n",
    "            return ranked_candidates\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            return candidates[:3]  # Fallback to the first 3 candidates\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying model: {e}\")\n",
    "        return candidates[:3]  # Fallback to the first 3 candidates\n",
    "\n",
    "def save_health_endpoints(health_endpoints, file_path):\n",
    "    \"\"\"\n",
    "    Save the selected health endpoints to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        health_endpoints (list): The list of health endpoints.\n",
    "        file_path (str): Path to save the JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(health_endpoints, file, indent=4)\n",
    "        print(f\"Health endpoints saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save health endpoints: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to find, rank, and save heartbeat endpoint candidates.\n",
    "    \"\"\"\n",
    "    # Load the parsed OpenAPI spec JSON file\n",
    "    try:\n",
    "        with open(parsed_spec_path, \"r\") as file:\n",
    "            parsed_spec = json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load parsed spec: {e}\")\n",
    "        return\n",
    "\n",
    "    # Find candidate endpoints\n",
    "    candidates = find_candidate_endpoints(parsed_spec)\n",
    "\n",
    "    if not candidates:\n",
    "        print(\"No candidate heartbeat endpoints found.\")\n",
    "        return\n",
    "\n",
    "    # Query the model for refined ranking\n",
    "    ranked_candidates = query_model_for_ranking(candidates)\n",
    "\n",
    "    # Save the top 3 candidates to a new JSON file\n",
    "    save_health_endpoints(ranked_candidates[:3], health_endpoints_path)\n",
    "\n",
    "    # Print the top 3 candidates\n",
    "    print(\"Top 3 Heartbeat Endpoint Candidates:\")\n",
    "    for i, candidate in enumerate(ranked_candidates[:3], start=1):\n",
    "        print(f\"{i}. Path: {candidate.get('path')}, Method: {candidate.get('method')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36297208-d541-4d94-9300-9701203ed65e",
   "metadata": {},
   "source": [
    "## 4 - Test Heartbeat Endpoints\n",
    "  - Appends endpoints_health.json with a list of the endpoints that were up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b880d75-15b0-493a-8e87-abde6b9077ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up endpoints successfully appended to: /m2-data/jupyterNotebooks/api/test_runs/vampi-20250101/endpoints_health.json\n",
      "Health Check Results:\n",
      "/createdb: Application is UP\n",
      "/: Application is UP\n",
      "/users/v1: Application is UP\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Test the endpoints\n",
    "Added if requests is successful\n",
    "\n",
    "input - parsed_spec.json\n",
    "output - appends endpoints_health.json\n",
    "'''\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "parsed_spec_path = f\"{output_folder}parsed_spec.json\"\n",
    "health_endpoints_path = f\"{output_folder}endpoints_health.json\"\n",
    "\n",
    "def get_base_url(parsed_spec_path):\n",
    "    \"\"\"\n",
    "    Retrieve the base URL from the parsed OpenAPI spec.\n",
    "\n",
    "    Args:\n",
    "        parsed_spec_path (str): Path to the parsed OpenAPI spec file.\n",
    "\n",
    "    Returns:\n",
    "        str: The base URL of the API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(parsed_spec_path, \"r\") as file:\n",
    "            parsed_spec = json.load(file)\n",
    "            servers = parsed_spec.get(\"servers\", [])\n",
    "            if servers and \"url\" in servers[0]:\n",
    "                return servers[0][\"url\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve base URL: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def run_health_checks(base_url, health_endpoints):\n",
    "    \"\"\"\n",
    "    Test the provided health endpoints to determine if the application is running.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL of the API.\n",
    "        health_endpoints (list): A list of health endpoint definitions, each containing \"path\" and \"method\".\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with endpoint results, indicating if the application is up.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for endpoint in health_endpoints:\n",
    "        path = endpoint.get(\"path\")\n",
    "        method = endpoint.get(\"method\", \"GET\").upper()\n",
    "        full_url = f\"{base_url}{path}\"  # Combine base URL and endpoint path\n",
    "\n",
    "        try:\n",
    "            # Send the request to the endpoint\n",
    "            response = requests.request(method, full_url)\n",
    "            \n",
    "            # Check if the response status code is 200\n",
    "            if response.status_code == 200:\n",
    "                results[path] = \"Application is UP\"\n",
    "            else:\n",
    "                results[path] = f\"Unexpected status code: {response.status_code}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            results[path] = f\"Error: {e}\"\n",
    "\n",
    "    return results\n",
    "\n",
    "def append_up_endpoints_to_file(up_endpoints, file_path):\n",
    "    \"\"\"\n",
    "    Append the endpoints that are up to the existing endpoints_health.json file.\n",
    "\n",
    "    Args:\n",
    "        up_endpoints (list): A list of endpoints that are up.\n",
    "        file_path (str): Path to the endpoints_health.json file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            existing_data = json.load(file)\n",
    "    except Exception:\n",
    "        existing_data = []\n",
    "\n",
    "    # Append the up endpoints\n",
    "    existing_data.extend(up_endpoints)\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(existing_data, file, indent=4)\n",
    "        print(f\"Up endpoints successfully appended to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to append up endpoints: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load health endpoints, run health checks, and update the endpoints file.\n",
    "    \"\"\"\n",
    "    # Retrieve the base URL\n",
    "    base_url = get_base_url(parsed_spec_path)\n",
    "    if not base_url:\n",
    "        print(\"Base URL not found. Cannot perform health checks.\")\n",
    "        return\n",
    "\n",
    "    # Load the health endpoints JSON file\n",
    "    try:\n",
    "        with open(health_endpoints_path, \"r\") as file:\n",
    "            health_endpoints = json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load health endpoints: {e}\")\n",
    "        return\n",
    "\n",
    "    # Run health checks\n",
    "    results = run_health_checks(base_url, health_endpoints)\n",
    "\n",
    "    # Filter endpoints that are up\n",
    "    up_endpoints = [\n",
    "        {\"path\": path, \"method\": health_endpoints[i].get(\"method\", \"GET\")}\n",
    "        for i, (path, status) in enumerate(results.items())\n",
    "        if \"Application is UP\" in status\n",
    "    ]\n",
    "\n",
    "    # Append up endpoints to the file\n",
    "    append_up_endpoints_to_file(up_endpoints, health_endpoints_path)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Health Check Results:\")\n",
    "    for path, status in results.items():\n",
    "        print(f\"{path}: {status}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d0d749-d752-456e-b7c4-e0b1a38e1fbe",
   "metadata": {},
   "source": [
    "## 5 - Determine User Registration Endpoints\n",
    "Determine API endpoints for user registration\n",
    "\n",
    "worked and then an LLM issue. \n",
    "\n",
    "TODO - fix prompt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "361bd197-bf44-48ae-8423-0bddc47ddb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query LLM\n",
      "model :  llama3.2:3b\n",
      "prompt:  From the following API paths and their fields, identify the most likely user registration endpoint. A user registration endpoint typically accepts input fields like 'username', 'email', and 'password' and returns a success response upon creating a new user. Return the result as a JSON object with keys 'path' and 'method'.\n",
      "\n",
      "Endpoints:\n",
      "[\n",
      "  {\n",
      "    \"path\": \"/users/v1/register\",\n",
      "    \"method\": \"POST\",\n",
      "    \"fields\": [\n",
      "      \"username\",\n",
      "      \"password\",\n",
      "      \"email\"\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "\n",
      "\n",
      "Fallback: Using the first pre-filtered endpoint.\n",
      "User registration endpoint saved to: /m2-data/jupyterNotebooks/api/test_runs/vampi-20250101/endpoint_user_reg.json\n",
      "User registration endpoint successfully identified and saved.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Determine the user registration endpoint\n",
    "\n",
    "Tries LLM but has a Python fallback method\n",
    "input - parsed_spec.json\n",
    "output - endpoint_user_reg.json\n",
    "\n",
    "TODO\n",
    "Fix LLM issue, worked then stopped?\n",
    "'''\n",
    "\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# File paths\n",
    "# base_path = \"/m2-data/jupyterNotebooks/api/test_runs/vampi-1/\"\n",
    "parsed_spec_path = f\"{output_folder}parsed_spec.json\"\n",
    "user_reg_endpoint_path = f\"{output_folder}endpoint_user_reg.json\"\n",
    "model_url = \"http://localhost:11434/api/generate\"  # Ollama API endpoint\n",
    "# model_name = \"qwen2.5-coder:7b\"\n",
    "# model_name = \"tinyllama:latest\"\n",
    "\n",
    "\n",
    "\n",
    "def find_user_registration_endpoint(parsed_spec, model_name=model_name):\n",
    "    \"\"\"\n",
    "    Use the LLM to determine a user registration endpoint from the parsed OpenAPI spec.\n",
    "\n",
    "    Args:\n",
    "        parsed_spec (dict): The parsed OpenAPI spec JSON content.\n",
    "        model_name (str): The name of the LLM model to query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The identified user registration endpoint.\n",
    "    \"\"\"\n",
    "    # Pre-filter relevant data\n",
    "    endpoints = parsed_spec.get(\"endpoints\", [])\n",
    "    relevant_endpoints = []\n",
    "\n",
    "    for endpoint in endpoints:\n",
    "        path = endpoint.get(\"path\")\n",
    "        method = endpoint.get(\"method\")\n",
    "        request_body = endpoint.get(\"requestBody\", {}).get(\"application/json\", {}).get(\"schema\", {})\n",
    "        fields = request_body.get(\"properties\", {})\n",
    "\n",
    "        # Check for the required fields\n",
    "        if all(key in fields for key in [\"username\", \"password\", \"email\"]):\n",
    "            relevant_endpoints.append({\n",
    "                \"path\": path,\n",
    "                \"method\": method.upper(),\n",
    "                \"fields\": list(fields.keys())\n",
    "            })\n",
    "\n",
    "    if not relevant_endpoints:\n",
    "        print(\"No endpoints with user registration fields found in pre-filtering.\")\n",
    "        return {}\n",
    "\n",
    "    # Updated prompt for the LLM\n",
    "    prompt = (\n",
    "        \"From the following API paths and their fields, identify the most likely user registration endpoint. \"\n",
    "        \"A user registration endpoint typically accepts input fields like 'username', 'email', and 'password' \"\n",
    "        \"and returns a success response upon creating a new user. Return the result as a JSON object with keys \"\n",
    "        \"'path' and 'method'.\\n\\n\"\n",
    "        f\"Endpoints:\\n{json.dumps(relevant_endpoints, indent=2)}\\n\\n\"\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Query the model\n",
    "        print(\"query LLM\")\n",
    "        print(\"model : \", model_name)\n",
    "        # print(\"prompt: \", prompt)\n",
    "        response = requests.post(model_url, json=payload, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Process the streamed response incrementally\n",
    "        result = \"\"\n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                try:\n",
    "                    # Decode each line and append to result\n",
    "                    result += chunk.decode('utf-8')\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        # Attempt to parse the JSON response\n",
    "        try:\n",
    "            endpoint = json.loads(result)\n",
    "            if \"path\" in endpoint and \"method\" in endpoint:\n",
    "                return endpoint\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback to the first relevant endpoint\n",
    "    if relevant_endpoints:\n",
    "        print(\"Fallback: Using the first pre-filtered endpoint.\")\n",
    "    return relevant_endpoints[0] if relevant_endpoints else {}\n",
    "\n",
    "def save_user_registration_endpoint(endpoint, file_path):\n",
    "    \"\"\"\n",
    "    Save the identified user registration endpoint to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        endpoint (dict): The user registration endpoint.\n",
    "        file_path (str): Path to save the JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(endpoint, file, indent=4)\n",
    "        print(f\"User registration endpoint saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save user registration endpoint: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to analyze the spec and save the user registration endpoint.\n",
    "    \"\"\"\n",
    "    # Load the parsed OpenAPI spec JSON file\n",
    "    try:\n",
    "        with open(parsed_spec_path, \"r\") as file:\n",
    "            parsed_spec = json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load parsed spec: {e}\")\n",
    "        return\n",
    "\n",
    "    # Use the LLM to find the user registration endpoint\n",
    "    user_registration_endpoint = find_user_registration_endpoint(parsed_spec, model_name)\n",
    "\n",
    "    if not user_registration_endpoint:\n",
    "        print(\"No user registration endpoint identified.\")\n",
    "        return\n",
    "\n",
    "    # Save the identified endpoint to a JSON file\n",
    "    save_user_registration_endpoint(user_registration_endpoint, user_reg_endpoint_path)\n",
    "    print(\"User registration endpoint successfully identified and saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce472154-1300-4f52-b656-ee68a71b3056",
   "metadata": {},
   "source": [
    "## 6 - Register Users\n",
    "Register users and store the data for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93e81ca-0324-43c3-a570-864a260c5bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered users saved to: /m2-data/jupyterNotebooks/api/test_runs/vampi-20250101/registered_user_accounts.json\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Register users\n",
    "- Set how many (default is 3)\n",
    "- uses test domain and user bases for names\n",
    "\n",
    "Stores all date used in the JSON file\n",
    "\n",
    "input \n",
    "    - parsed_spec.json\n",
    "    - registered_user_accounts.json\n",
    "output - registered_user_accounts.json\n",
    "'''\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "import string\n",
    "\n",
    "num_users_to_create = 3  # Initial number of users to create\n",
    "\n",
    "# File paths\n",
    "user_reg_endpoint_path = f\"{output_folder}endpoint_user_reg.json\"\n",
    "registered_users_path = f\"{output_folder}registered_user_accounts.json\"\n",
    "parsed_spec_path = f\"{output_folder}parsed_spec.json\"\n",
    "\n",
    "def load_base_url():\n",
    "    \"\"\"\n",
    "    Load the base URL from the parsed OpenAPI spec JSON file.\n",
    "\n",
    "    Returns:\n",
    "        str: The base URL of the API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(parsed_spec_path, \"r\") as file:\n",
    "            parsed_spec = json.load(file)\n",
    "            servers = parsed_spec.get(\"servers\", [])\n",
    "            if servers and \"url\" in servers[0]:\n",
    "                return servers[0][\"url\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load base URL: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def generate_random_string(length=8):\n",
    "    \"\"\"\n",
    "    Generate a random string of given length.\n",
    "\n",
    "    Args:\n",
    "        length (int): Length of the string.\n",
    "\n",
    "    Returns:\n",
    "        str: Randomly generated string.\n",
    "    \"\"\"\n",
    "    return ''.join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "def generate_user_data():\n",
    "    \"\"\"\n",
    "    Generate a dictionary with user registration data.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing user registration fields and values.\n",
    "    \"\"\"\n",
    "    # username = generate_random_string()\n",
    "    username = f\"{base_test_username}-{generate_random_string()}\"\n",
    "    password = generate_random_string(12)  # Longer password for security\n",
    "    email = f\"{username}@{test_email_domain}\"\n",
    "    return {\n",
    "        \"username\": username,\n",
    "        \"password\": password,\n",
    "        \"email\": email\n",
    "    }\n",
    "\n",
    "def load_user_registration_endpoint():\n",
    "    \"\"\"\n",
    "    Load the user registration endpoint from the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The user registration endpoint details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(user_reg_endpoint_path, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load user registration endpoint: {e}\")\n",
    "        return {}\n",
    "\n",
    "def save_registered_users(users):\n",
    "    \"\"\"\n",
    "    Save the registered user account details to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        users (list): A list of registered user account details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(registered_users_path, \"w\") as file:\n",
    "            json.dump(users, file, indent=4)\n",
    "        print(f\"Registered users saved to: {registered_users_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save registered users: {e}\")\n",
    "\n",
    "def register_users(endpoint, base_url, num_users):\n",
    "    \"\"\"\n",
    "    Register users using the specified endpoint.\n",
    "\n",
    "    Args:\n",
    "        endpoint (dict): The user registration endpoint.\n",
    "        base_url (str): The base URL of the API.\n",
    "        num_users (int): Number of users to create.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing user account details, request payloads, and responses.\n",
    "    \"\"\"\n",
    "    path = endpoint.get(\"path\", \"\")\n",
    "    method = endpoint.get(\"method\", \"POST\").upper()\n",
    "\n",
    "    if not base_url or not path:\n",
    "        print(\"Invalid user registration endpoint configuration.\")\n",
    "        return []\n",
    "\n",
    "    url = f\"{base_url}{path}\"\n",
    "    users = []\n",
    "\n",
    "    for _ in range(num_users):\n",
    "        user_data = generate_user_data()\n",
    "        try:\n",
    "            response = requests.request(method, url, json=user_data)\n",
    "            status = \"Success\" if response.status_code == 200 else f\"Failed ({response.status_code})\"\n",
    "            users.append({\n",
    "                \"request\": user_data,\n",
    "                \"response\": response.json() if response.headers.get(\"Content-Type\") == \"application/json\" else response.text,\n",
    "                \"registration_status\": status\n",
    "            })\n",
    "        except Exception as e:\n",
    "            users.append({\n",
    "                \"request\": user_data,\n",
    "                \"response\": str(e),\n",
    "                \"registration_status\": f\"Error: {e}\"\n",
    "            })\n",
    "\n",
    "    return users\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to create users.\n",
    "    \"\"\"\n",
    "    # Load the base URL\n",
    "    base_url = load_base_url()\n",
    "    if not base_url:\n",
    "        print(\"No base URL found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Load the user registration endpoint\n",
    "    endpoint = load_user_registration_endpoint()\n",
    "    if not endpoint:\n",
    "        print(\"No user registration endpoint found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Register users\n",
    "    registered_users = register_users(endpoint, base_url, num_users_to_create)\n",
    "\n",
    "    # Save the registered users to a file\n",
    "    save_registered_users(registered_users)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd569c0-bbc4-4146-aa21-130d036a572b",
   "metadata": {},
   "source": [
    "## 7 - User Endpoint Detection\n",
    "Try to determine and endpoints that are user specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086fcb6-e0a2-43da-96f0-94a415b4fb80",
   "metadata": {},
   "source": [
    "### Option 1 -Script based User Endpoint Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bcfb404-8075-408a-aa9c-c839e49cebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved programmatic endpoints to /m2-data/jupyterNotebooks/api/test_runs/vampi-20250101/programmatic_user_endpoints.json\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Try to determine user related endpoints\n",
    "input - API spec\n",
    "output - programmatic_user_endpoints.json\n",
    "\n",
    "TODO\n",
    "fix parsing, still returning endpoints that are not user related '/' \n",
    "move to parsed_json file as a key that can be true or false\n",
    "'''\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "\n",
    "def load_openapi_spec():\n",
    "    \"\"\"\n",
    "    Load OpenAPI specification from the provided spec file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Parsed OpenAPI specification.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(api_spec_path, \"r\") as file:\n",
    "            if api_spec_path.endswith(('.yml', '.yaml')):\n",
    "                return yaml.safe_load(file)\n",
    "            else:\n",
    "                return json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading OpenAPI spec: {e}\")\n",
    "    return {}\n",
    "\n",
    "def extract_endpoints_with_fields(openapi_spec):\n",
    "    \"\"\"\n",
    "    Extract endpoints with detailed required fields from the OpenAPI spec.\n",
    "\n",
    "    Args:\n",
    "        openapi_spec (dict): Parsed OpenAPI specification.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of endpoint dictionaries with paths, methods, and required fields.\n",
    "    \"\"\"\n",
    "    endpoints = []\n",
    "    paths = openapi_spec.get(\"paths\", {})\n",
    "\n",
    "    for path, methods in paths.items():\n",
    "        for method, details in methods.items():\n",
    "            endpoint_info = {\n",
    "                \"path\": path,\n",
    "                \"method\": method.upper(),\n",
    "                \"parameters\": {},\n",
    "            }\n",
    "\n",
    "            # Extract parameters from requestBody\n",
    "            request_body = details.get(\"requestBody\", {}).get(\"content\", {}).get(\"application/json\", {})\n",
    "            schema = request_body.get(\"schema\", {}).get(\"properties\", {})\n",
    "\n",
    "            if schema:\n",
    "                for field, field_details in schema.items():\n",
    "                    endpoint_info[\"parameters\"][field] = field_details.get(\"example\", \"\")\n",
    "\n",
    "            endpoints.append(endpoint_info)\n",
    "\n",
    "    return endpoints\n",
    "\n",
    "def save_programmatic_endpoints(endpoints):\n",
    "    \"\"\"\n",
    "    Save extracted endpoints to the programmatic_user_endpoints.json file.\n",
    "\n",
    "    Args:\n",
    "        endpoints (list): List of endpoint dictionaries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(f\"{output_folder}programmatic_user_endpoints.json\", \"w\") as file:\n",
    "            json.dump(endpoints, file, indent=4)\n",
    "        print(f\"Saved programmatic endpoints to {output_folder}programmatic_user_endpoints.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving programmatic endpoints: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to generate programmatic endpoints.\n",
    "    \"\"\"\n",
    "    openapi_spec = load_openapi_spec()\n",
    "    if not openapi_spec:\n",
    "        print(\"OpenAPI spec could not be loaded. Exiting.\")\n",
    "        return\n",
    "\n",
    "    endpoints = extract_endpoints_with_fields(openapi_spec)\n",
    "    if not endpoints:\n",
    "        print(\"No endpoints found in the OpenAPI spec. Exiting.\")\n",
    "        return\n",
    "\n",
    "    save_programmatic_endpoints(endpoints)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed4b46-4f7c-4384-a23e-46711858a458",
   "metadata": {},
   "source": [
    "### Option 2 - LLM based User Endpoint Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d32e0a80-2faa-44cd-af84-c98234df7fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model :  llama3.2:3b\n",
      "sending payload to LLM\n",
      "JSON parsing error: Extra data: line 1 column 100 (char 99)\n",
      "LLM results saved to: /m2-data/jupyterNotebooks/api/test_runs/vampi-20250101/llm_user_endpoints.json\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Try to determine user related endpoints\n",
    "input - API spec\n",
    "output - programmatic_user_endpoints.json\n",
    "\n",
    "TODO\n",
    "fix LLM integration, returing an empty request, see debug calls\n",
    "move to parsed_json file as a key that can be true or false\n",
    "'''\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "import requests\n",
    "\n",
    "# File paths\n",
    "# api_spec_path = f\"/m2-data/jupyterNotebooks/api/spec/openapi3Vampi.json\"  \n",
    "# api_spec_path = f\"/m2-data/jupyterNotebooks/api/spec/openapi3Vampi.yml\"  \n",
    "llm_results_path = f\"{output_folder}llm_user_endpoints.json\"\n",
    "\n",
    "\n",
    "# LLM configuration\n",
    "llm_url = \"http://localhost:11434/api/generate\"  # Ollama API endpoint\n",
    "prompt_task = (\n",
    "    \"Analyze the following OpenAPI specification to identify user-related endpoints that require authentication. \"\n",
    "    \"Focus on endpoints related to users, such as account management, authentication, or profile operations. \"\n",
    "    \"For each endpoint, specify the HTTP method, path, and whether it requires authentication based on the spec's details.\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_openapi_spec(file_path):\n",
    "    \"\"\"\n",
    "    Load the OpenAPI spec from a YAML or JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the OpenAPI spec file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The OpenAPI spec content.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            if file_path.endswith(\".yml\") or file_path.endswith(\".yaml\"):\n",
    "                return yaml.safe_load(file)\n",
    "            elif file_path.endswith(\".json\"):\n",
    "                return json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load OpenAPI spec: {e}\")\n",
    "        return {}\n",
    "\n",
    "def query_llm_for_user_endpoints(openapi_spec, llm_url, prompt_task):\n",
    "    \"\"\"\n",
    "    Query the LLM to analyze the OpenAPI spec for user-related endpoints requiring authentication.\n",
    "\n",
    "    Args:\n",
    "        openapi_spec (dict): The OpenAPI spec content.\n",
    "        llm_url (str): The LLM API endpoint.\n",
    "        prompt_task (str): The task description for the LLM.\n",
    "\n",
    "    Returns:\n",
    "        dict: The LLM's analysis results.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"{prompt_task}\\\\n\\\\n\"\n",
    "        f\"OpenAPI Spec:\\\\n{json.dumps(openapi_spec, indent=2)}\\\\n\\\\n\"\n",
    "        \"Return the results as a JSON object with fields: path, method, and requires_authentication.\"\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    print(\"model : \", model_name)\n",
    "    # print(\"prompt : \", prompt)\n",
    "    print(\"sending payload to LLM\")\n",
    "    try:\n",
    "        response = requests.post(llm_url, json=payload, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Stream and assemble the response incrementally\n",
    "        result = \"\"\n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                result += chunk.decode('utf-8')\n",
    "\n",
    "        # Debug: Print raw response for troubleshooting\n",
    "        # print(f\"Raw LLM Response: {result}\")\n",
    "\n",
    "        # Attempt to parse the JSON response\n",
    "        return json.loads(result)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error: {e}\")\n",
    "        # uncomment to debug\n",
    "        # print(f\"Raw LLM Response: {result}\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM: {e}\")\n",
    "        return {}\n",
    "\n",
    "def save_llm_results(results, file_path):\n",
    "    \"\"\"\n",
    "    Save the LLM results to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        results (dict): The LLM's analysis results.\n",
    "        file_path (str): Path to save the JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(results, file, indent=4)\n",
    "        print(f\"LLM results saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save LLM results: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to analyze the OpenAPI spec with an LLM.\n",
    "    \"\"\"\n",
    "    # Load the OpenAPI spec\n",
    "    openapi_spec = load_openapi_spec(api_spec_path)\n",
    "    if not openapi_spec:\n",
    "        print(\"No OpenAPI spec loaded. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Query the LLM for user-related endpoints\n",
    "    llm_results = query_llm_for_user_endpoints(openapi_spec, llm_url, prompt_task)\n",
    "\n",
    "    # Save the LLM's analysis results\n",
    "    save_llm_results(llm_results, llm_results_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77210b8a-5c7d-4158-8767-5ccedc2cba24",
   "metadata": {},
   "source": [
    "## 8 - Get User Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0853968e-ab8d-4358-a6a5-25cbd7f51bd4",
   "metadata": {},
   "source": [
    "### Option 1 - ID Token field via API Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f385f26-4441-44ef-b96f-fcc7c98b2ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified token field dynamically: auth_token -> eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3MzU3NzI5NDMsImlhdCI6MTczNTc3Mjg4Mywic3ViIjoiYWRiMTIzLXRpcHpkOWN1In0.UP9XaIuL2yFy4cb476_0IR-Zruz-tPov9nDFMA75Ok8\n",
      "Updated token field name in user JSON: auth_token\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import yaml\n",
    "import requests\n",
    "\n",
    "def load_base_url():\n",
    "    \"\"\"\n",
    "    Load the base URL from the OpenAPI spec file.\n",
    "\n",
    "    Returns:\n",
    "        str: The base URL of the API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(api_spec_path, \"r\") as file:\n",
    "            if api_spec_path.endswith(('.yml', '.yaml')):\n",
    "                parsed_spec = yaml.safe_load(file)\n",
    "            else:\n",
    "                parsed_spec = json.load(file)\n",
    "            servers = parsed_spec.get(\"servers\", [])\n",
    "            if servers and \"url\" in servers[0]:\n",
    "                return servers[0][\"url\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load base URL: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def login_user(base_url, username, password):\n",
    "    \"\"\"\n",
    "    Log in a user to obtain a JWT token.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL of the API.\n",
    "        username (str): The username of the user.\n",
    "        password (str): The password of the user.\n",
    "\n",
    "    Returns:\n",
    "        dict: The full response JSON from the login API.\n",
    "    \"\"\"\n",
    "    login_endpoint = f\"{base_url}/users/v1/login\"\n",
    "    payload = {\"username\": username, \"password\": password}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(login_endpoint, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Login failed: {response.status_code}, {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging in: {e}\")\n",
    "    return {}\n",
    "\n",
    "def identify_token_field(response_json):\n",
    "    \"\"\"\n",
    "    Dynamically identify the token field in the login response.\n",
    "\n",
    "    Args:\n",
    "        response_json (dict): The response JSON from the login API.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The field name and token value if identified, None otherwise.\n",
    "    \"\"\"\n",
    "    for key, value in response_json.items():\n",
    "        if \"token\" in key.lower() and isinstance(value, str):\n",
    "            return key, value\n",
    "    return None, None\n",
    "\n",
    "def update_token_field_name(field_name):\n",
    "    \"\"\"\n",
    "    Update the token field name in the registered users JSON file.\n",
    "\n",
    "    Args:\n",
    "        field_name (str): The name of the token field.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(registered_users_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Add the token_field globally\n",
    "        if isinstance(data, list):\n",
    "            data = {\"token_field\": field_name, \"users\": data}\n",
    "        else:\n",
    "            data[\"token_field\"] = field_name\n",
    "\n",
    "        with open(registered_users_path, \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "        print(f\"Updated token field name in user JSON: {field_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to update token field name: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to log in and identify the token field dynamically.\n",
    "    \"\"\"\n",
    "    base_url = load_base_url()\n",
    "    if not base_url:\n",
    "        print(\"Base URL not found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Load a user from the registered user accounts\n",
    "    try:\n",
    "        with open(registered_users_path, \"r\") as file:\n",
    "            users = json.load(file)\n",
    "            if not users:\n",
    "                print(\"No users found in the registered user accounts file.\")\n",
    "                return\n",
    "\n",
    "            # Use the first successfully registered user\n",
    "            valid_users = [user for user in users if user.get(\"registration_status\") == \"Success\"]\n",
    "            if not valid_users:\n",
    "                print(\"No valid registered users found.\")\n",
    "                return\n",
    "\n",
    "            user = valid_users[0]\n",
    "            username = user[\"request\"][\"username\"]\n",
    "            password = user[\"request\"][\"password\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading users: {e}\")\n",
    "        return\n",
    "\n",
    "    # Log in the user\n",
    "    response_json = login_user(base_url, username, password)\n",
    "\n",
    "    # Check if login was successful\n",
    "    if response_json.get(\"status\", \"\").lower() != \"success\":\n",
    "        print(f\"Login failed. Response: {response_json}\")\n",
    "        return\n",
    "\n",
    "    # Identify the token field\n",
    "    field_name, token = identify_token_field(response_json)\n",
    "    if token:\n",
    "        print(f\"Identified token field dynamically: {field_name} -> {token}\")\n",
    "        update_token_field_name(field_name)\n",
    "    else:\n",
    "        print(f\"Token field not found in response: {response_json}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645e10c-dc6d-4e16-aa12-4feae145100b",
   "metadata": {},
   "source": [
    "### Option 2 - ID Token via Script\n",
    "\n",
    "Currently broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "321d9778-c2b6-49dd-a7bb-9d6712339007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading users: 'str' object has no attribute 'get'\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# File paths\n",
    "parsed_spec_path = f\"{output_folder}parsed_spec.json\"\n",
    "registered_users_path = f\"{output_folder}registered_user_accounts.json\"\n",
    "\n",
    "def load_base_url():\n",
    "    \"\"\"\n",
    "    Load the base URL from the parsed OpenAPI spec JSON file.\n",
    "\n",
    "    Returns:\n",
    "        str: The base URL of the API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(parsed_spec_path, \"r\") as file:\n",
    "            parsed_spec = json.load(file)\n",
    "            servers = parsed_spec.get(\"servers\", [])\n",
    "            if servers and \"url\" in servers[0]:\n",
    "                return servers[0][\"url\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load base URL: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def login_user(base_url, username, password):\n",
    "    \"\"\"\n",
    "    Log in a user to obtain a JWT token.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL of the API.\n",
    "        username (str): The username of the user.\n",
    "        password (str): The password of the user.\n",
    "\n",
    "    Returns:\n",
    "        dict: The full response JSON from the login API.\n",
    "    \"\"\"\n",
    "    login_endpoint = f\"{base_url}/users/v1/login\"\n",
    "    payload = {\"username\": username, \"password\": password}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(login_endpoint, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Login failed: {response.status_code}, {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging in: {e}\")\n",
    "    return {}\n",
    "\n",
    "def identify_token_field(response_json):\n",
    "    \"\"\"\n",
    "    Dynamically identify the token field in the login response.\n",
    "\n",
    "    Args:\n",
    "        response_json (dict): The response JSON from the login API.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The field name and token value if identified, None otherwise.\n",
    "    \"\"\"\n",
    "    for key, value in response_json.items():\n",
    "        if \"token\" in key.lower() and isinstance(value, str):\n",
    "            return key, value\n",
    "    return None, None\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to log in and identify the token field dynamically.\n",
    "    \"\"\"\n",
    "    base_url = load_base_url()\n",
    "    if not base_url:\n",
    "        print(\"Base URL not found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Load a user from the registered user accounts\n",
    "    try:\n",
    "        with open(registered_users_path, \"r\") as file:\n",
    "            users = json.load(file)\n",
    "            if not users:\n",
    "                print(\"No users found in the registered user accounts file.\")\n",
    "                return\n",
    "\n",
    "            # Use the first successfully registered user\n",
    "            valid_users = [user for user in users if user.get(\"registration_status\") == \"Success\"]\n",
    "            if not valid_users:\n",
    "                print(\"No valid registered users found.\")\n",
    "                return\n",
    "\n",
    "            user = valid_users[0]\n",
    "            username = user[\"request\"][\"username\"]\n",
    "            password = user[\"request\"][\"password\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading users: {e}\")\n",
    "        return\n",
    "\n",
    "    # Log in the user\n",
    "    response_json = login_user(base_url, username, password)\n",
    "\n",
    "    # Check if login was successful\n",
    "    if response_json.get(\"status\", \"\").lower() != \"success\":\n",
    "        print(f\"Login failed. Response: {response_json}\")\n",
    "        return\n",
    "\n",
    "    # Identify the token field\n",
    "    field_name, token = identify_token_field(response_json)\n",
    "    if token:\n",
    "        print(f\"Identified token field dynamically: {field_name} -> {token}\")\n",
    "    else:\n",
    "        print(f\"Token field not found in response: {response_json}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b52e2d-a3f8-48bb-b728-9f68f61be67c",
   "metadata": {},
   "source": [
    "### Option 3 - LLM Assisted Token ID\n",
    "Also broken :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e51d31bd-384e-467b-ad6e-102e4600df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading users: 'str' object has no attribute 'get'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# File paths\n",
    "parsed_spec_path = f\"{output_folder}parsed_spec.json\"\n",
    "registered_users_path = f\"{output_folder}registered_user_accounts.json\"\n",
    "\n",
    "# LLM configuration\n",
    "llm_url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "def load_base_url():\n",
    "    \"\"\"\n",
    "    Load the base URL from the parsed OpenAPI spec JSON file.\n",
    "\n",
    "    Returns:\n",
    "        str: The base URL of the API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(parsed_spec_path, \"r\") as file:\n",
    "            parsed_spec = json.load(file)\n",
    "            servers = parsed_spec.get(\"servers\", [])\n",
    "            if servers and \"url\" in servers[0]:\n",
    "                return servers[0][\"url\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load base URL: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def login_user(base_url, username, password):\n",
    "    \"\"\"\n",
    "    Log in a user to obtain a JWT token.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL of the API.\n",
    "        username (str): The username of the user.\n",
    "        password (str): The password of the user.\n",
    "\n",
    "    Returns:\n",
    "        dict: The full response JSON from the login API.\n",
    "    \"\"\"\n",
    "    login_endpoint = f\"{base_url}/users/v1/login\"\n",
    "    payload = {\"username\": username, \"password\": password}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(login_endpoint, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Login failed: {response.status_code}, {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging in: {e}\")\n",
    "    return {}\n",
    "\n",
    "def query_llm_for_token_field(response_json):\n",
    "    \"\"\"\n",
    "    Query the LLM to identify the token field in the response JSON.\n",
    "\n",
    "    Args:\n",
    "        response_json (dict): The response JSON from the login API.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the field name and token value.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Analyze the following JSON response from a login API call to identify the field that contains the \"\n",
    "        \"authentication token. Return the name of the field and its value as a JSON object with keys 'field_name' and 'token'.\\n\\n\"\n",
    "        f\"Response JSON:\\n{json.dumps(response_json, indent=2)}\"\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(llm_url, json=payload, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Stream and assemble the response incrementally\n",
    "        result = \"\"\n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                result += chunk.decode('utf-8')\n",
    "\n",
    "        # Parse the LLM result as JSON\n",
    "        return json.loads(result.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM: {e}\")\n",
    "    return {}\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to log in and identify the token field using an LLM.\n",
    "    \"\"\"\n",
    "    base_url = load_base_url()\n",
    "    if not base_url:\n",
    "        print(\"Base URL not found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Load a user from the registered user accounts\n",
    "    try:\n",
    "        with open(registered_users_path, \"r\") as file:\n",
    "            users = json.load(file)\n",
    "            if not users:\n",
    "                print(\"No users found in the registered user accounts file.\")\n",
    "                return\n",
    "\n",
    "            # Use the first successfully registered user\n",
    "            valid_users = [user for user in users if user.get(\"registration_status\") == \"Success\"]\n",
    "            if not valid_users:\n",
    "                print(\"No valid registered users found.\")\n",
    "                return\n",
    "\n",
    "            user = valid_users[0]\n",
    "            username = user[\"request\"][\"username\"]\n",
    "            password = user[\"request\"][\"password\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading users: {e}\")\n",
    "        return\n",
    "\n",
    "    # Log in the user\n",
    "    response_json = login_user(base_url, username, password)\n",
    "\n",
    "    # Check if login was successful\n",
    "    if response_json.get(\"status\", \"\").lower() != \"success\":\n",
    "        print(f\"Login failed. Response: {response_json}\")\n",
    "        return\n",
    "\n",
    "    # Query the LLM for the token field\n",
    "    token_info = query_llm_for_token_field(response_json)\n",
    "    if token_info:\n",
    "        field_name = token_info.get(\"field_name\")\n",
    "        token = token_info.get(\"token\")\n",
    "        print(f\"Identified token field using LLM: {field_name} -> {token}\")\n",
    "    else:\n",
    "        print(f\"LLM could not identify token field in response: {response_json}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1cead4-4a67-48b5-a8ac-74939f1af43a",
   "metadata": {},
   "source": [
    "## 9 - Update User Tokens\n",
    "Generate tokens for tye users that were created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29670d14-c632-4e9f-b28d-c97bc4ecd158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated token for adb123-tipzd9cu: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3MzU3NzQ0NzEsImlhdCI6MTczNTc3NDQxMSwic3ViIjoiYWRiMTIzLXRpcHpkOWN1In0.WAI32nxq4LzUv9r_hUHrVig50Py-4UA8PLkj9ZPQMBQ\n",
      "Generated token for adb123-ttevesc3: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3MzU3NzQ0NzEsImlhdCI6MTczNTc3NDQxMSwic3ViIjoiYWRiMTIzLXR0ZXZlc2MzIn0.oUf2KjDSIYDisFsEQjMoXJBENViOMMcCNI_i7dmkuOE\n",
      "Generated token for adb123-yooh54nn: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3MzU3NzQ0NzEsImlhdCI6MTczNTc3NDQxMSwic3ViIjoiYWRiMTIzLXlvb2g1NG5uIn0.hBLqyObb_OtprwhgpMbjk3s2PcsxQinzOyAySBOIbSI\n",
      "Updated registered users JSON file with tokens.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Update the user info JSON file with tokens\n",
    "\n",
    "input - parsed_spec.json\n",
    "output - uupdates registered_user_accounts.json\n",
    "'''\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "def load_base_url():\n",
    "    \"\"\"\n",
    "    Load the base URL from the OpenAPI spec file.\n",
    "\n",
    "    Returns:\n",
    "        str: The base URL of the API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(api_spec_path, \"r\") as file:\n",
    "            if api_spec_path.endswith(('.yml', '.yaml')):\n",
    "                parsed_spec = yaml.safe_load(file)\n",
    "            else:\n",
    "                parsed_spec = json.load(file)\n",
    "            servers = parsed_spec.get(\"servers\", [])\n",
    "            if servers and \"url\" in servers[0]:\n",
    "                return servers[0][\"url\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load base URL: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def login_user(base_url, username, password):\n",
    "    \"\"\"\n",
    "    Log in a user to obtain a JWT token.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL of the API.\n",
    "        username (str): The username of the user.\n",
    "        password (str): The password of the user.\n",
    "\n",
    "    Returns:\n",
    "        dict: The full response JSON from the login API.\n",
    "    \"\"\"\n",
    "    login_endpoint = f\"{base_url}/users/v1/login\"\n",
    "    payload = {\"username\": username, \"password\": password}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(login_endpoint, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Login failed: {response.status_code}, {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging in: {e}\")\n",
    "    return {}\n",
    "\n",
    "def identify_token_field(response_json):\n",
    "    \"\"\"\n",
    "    Dynamically identify the token field in the login response.\n",
    "\n",
    "    Args:\n",
    "        response_json (dict): The response JSON from the login API.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The field name and token value if identified, None otherwise.\n",
    "    \"\"\"\n",
    "    for key, value in response_json.items():\n",
    "        if \"token\" in key.lower() and isinstance(value, str):\n",
    "            return key, value\n",
    "    return None, None\n",
    "\n",
    "def update_users_with_tokens(base_url):\n",
    "    \"\"\"\n",
    "    Update the registered users JSON file with tokens for all users.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL of the API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(registered_users_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        token_field = data.get(\"token_field\")\n",
    "        users = data.get(\"users\", [])\n",
    "\n",
    "        if not users:\n",
    "            print(\"No users found in the registered user accounts file.\")\n",
    "            return\n",
    "\n",
    "        for user in users:\n",
    "            if user.get(\"registration_status\") != \"Success\":\n",
    "                continue\n",
    "\n",
    "            username = user.get(\"request\", {}).get(\"username\")\n",
    "            password = user.get(\"request\", {}).get(\"password\")\n",
    "\n",
    "            if not username or not password:\n",
    "                print(f\"Missing username or password for user: {user}\")\n",
    "                continue\n",
    "\n",
    "            # Log in the user\n",
    "            response_json = login_user(base_url, username, password)\n",
    "\n",
    "            # Check if login was successful\n",
    "            if response_json.get(\"status\", \"\").lower() != \"success\":\n",
    "                print(f\"Login failed for user {username}. Response: {response_json}\")\n",
    "                continue\n",
    "\n",
    "            # Identify the token field\n",
    "            field_name, token = identify_token_field(response_json)\n",
    "            if token:\n",
    "                print(f\"Generated token for {username}: {token}\")\n",
    "                user[token_field] = token\n",
    "            else:\n",
    "                print(f\"Token field not found for user {username}. Response: {response_json}\")\n",
    "\n",
    "        # Save the updated users file\n",
    "        data[\"users\"] = users\n",
    "        with open(registered_users_path, \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "        print(\"Updated registered users JSON file with tokens.\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to update users with tokens: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to update users with tokens.\n",
    "    \"\"\"\n",
    "    base_url = load_base_url()\n",
    "    if not base_url:\n",
    "        print(\"Base URL not found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    update_users_with_tokens(base_url)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb34316-8224-4db5-93f5-28ae14777b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU",
   "language": "python",
   "name": "gpu_enabled"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
