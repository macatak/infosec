{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b47e03c-8369-48a0-842d-34c2aa9a37d4",
   "metadata": {},
   "source": [
    "# LLM Enhanced API testing  \n",
    "Perform security testing based on an OpenAPI spec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41323f2-4937-4204-98df-58fba54082e8",
   "metadata": {},
   "source": [
    "## 1 - Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3495d997-f708-490e-b1cf-761afa5b28d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API specification file :  /m2-data/jupyterNotebooks/api/spec/openapi3Vampi.yml\n",
      "output path :  /m2-data/jupyterNotebooks/api/test_runs/vampi-20241231/\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Set up the environment\n",
    "'''\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def create_output_folder():\n",
    "    \"\"\"\n",
    "    Create a timestamped folder for the output files.\n",
    "    \"\"\"\n",
    "    # TODO - need to rethink this\n",
    "    # long version\n",
    "    # timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # this will create a daily folder\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "    folder_name = f\"vampi-{timestamp}/\"\n",
    "    output_folder = os.path.join(output_base_path, folder_name)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    return output_folder\n",
    "\n",
    "## Paths\n",
    "# API spec path\n",
    "api_spec_path = \"/m2-data/jupyterNotebooks/api/spec/openapi3Vampi.yml\"\n",
    "# base output folder path\n",
    "output_base_path = \"/m2-data/jupyterNotebooks/api/test_runs/\"\n",
    "# create a new folder for this run\n",
    "output_folder = create_output_folder()\n",
    "\n",
    "#models\n",
    "model_name = \"qwen2.5-coder:7b\"\n",
    "# model_name = \"tinyllama:latest\"\n",
    "\n",
    "# test data setup\n",
    "test_email_domain = \"test.com\"\n",
    "base_test_username = \"adb123\"\n",
    "\n",
    "# print the paths\n",
    "print(\"API specification file : \", api_spec_path)\n",
    "print(\"output path : \", output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec917e3-f7f9-4505-86d8-7a7f71ef90cb",
   "metadata": {},
   "source": [
    "## 2 - Validate and parse the spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3813df16-c486-4d08-9f8a-db05c9675ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAPI spec validation successful.\n",
      "Parsed specification details saved to: /m2-data/jupyterNotebooks/api/test_runs/vampi-20241231/parsed_spec.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from openapi_spec_validator import validate_spec\n",
    "\n",
    "\n",
    "def validate_openapi_spec(file_path, output_folder):\n",
    "    \"\"\"\n",
    "    Validates the OpenAPI specification and attempts partial parsing on failure.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the OpenAPI specification file.\n",
    "        output_folder (str): Path to the output folder for logging.\n",
    "\n",
    "    Returns:\n",
    "        dict: The parsed OpenAPI specification (best effort), or an empty dict if parsing completely fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            if file_path.endswith('.json'):\n",
    "                spec = json.load(file)\n",
    "            elif file_path.endswith(('.yaml', '.yml')):\n",
    "                spec = yaml.safe_load(file)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format. Only JSON and YAML are allowed.\")\n",
    "\n",
    "        validate_spec(spec)\n",
    "        print(\"OpenAPI spec validation successful.\")\n",
    "        return spec\n",
    "\n",
    "    except (json.JSONDecodeError, yaml.YAMLError) as e:\n",
    "        error_message = f\"Failed to parse the specification file: {e}\"\n",
    "    except Exception as e:  # Generic handling for validation errors\n",
    "        error_message = f\"Validation error: {e}\"\n",
    "\n",
    "    # Log validation errors\n",
    "    log_file = os.path.join(output_folder, \"validation_errors.log\")\n",
    "    with open(log_file, 'w') as log:\n",
    "        log.write(error_message)\n",
    "    print(f\"Validation failed. Errors logged to: {log_file}\")\n",
    "\n",
    "    # Attempt to return partial spec if possible\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            if file_path.endswith('.json'):\n",
    "                return json.load(file)\n",
    "            elif file_path.endswith(('.yaml', '.yml')):\n",
    "                return yaml.safe_load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to perform partial parsing: {e}\")\n",
    "        return {}\n",
    "\n",
    "def parse_spec_details(spec):\n",
    "    \"\"\"\n",
    "    Parses the OpenAPI specification to extract servers, endpoints, and additional metadata.\n",
    "\n",
    "    Args:\n",
    "        spec (dict): The OpenAPI specification.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing servers, endpoints, and useful metadata.\n",
    "    \"\"\"\n",
    "    endpoints = []\n",
    "    servers = spec.get('servers', [])\n",
    "    info = spec.get('info', {})\n",
    "    tags = spec.get('tags', [])\n",
    "    security = spec.get('security', [])\n",
    "    external_docs = spec.get('externalDocs', {})\n",
    "\n",
    "    for path, methods in spec.get('paths', {}).items():\n",
    "        for method, details in methods.items():\n",
    "            endpoint_info = {\n",
    "                \"path\": path,\n",
    "                \"method\": method.upper(),\n",
    "                \"parameters\": details.get(\"parameters\", []),\n",
    "                \"requestBody\": details.get(\"requestBody\", {}).get(\"content\", {}),\n",
    "                \"responses\": details.get(\"responses\", {})\n",
    "            }\n",
    "            endpoints.append(endpoint_info)\n",
    "\n",
    "    return {\n",
    "        \"servers\": servers,\n",
    "        \"info\": info,\n",
    "        \"tags\": tags,\n",
    "        \"security\": security,\n",
    "        \"externalDocs\": external_docs,\n",
    "        \"endpoints\": endpoints\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to validate and parse the OpenAPI spec, saving output to JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate the spec\n",
    "    spec = validate_openapi_spec(api_spec_path, output_folder)\n",
    "    if not spec:\n",
    "        print(\"Failed to validate or parse the OpenAPI spec. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Parse spec details\n",
    "    parsed_data = parse_spec_details(spec)\n",
    "\n",
    "    # Save parsed data to a JSON file\n",
    "    output_file = os.path.join(output_folder, \"parsed_spec.json\")\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(parsed_data, file, indent=4)\n",
    "\n",
    "    print(f\"Parsed specification details saved to: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16dd29-29b8-4e7d-ae2c-3dd49ad57d48",
   "metadata": {},
   "source": [
    "## Health Checks - LLM Assisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95cbbea1-e7cb-455e-bd4b-e14a1375a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error: Expecting value: line 1 column 2 (char 1)\n",
      "Health endpoints saved to: /m2-data/jupyterNotebooks/api/test_runs/vampi-20241231/endpoints_health.json\n",
      "Top 3 Heartbeat Endpoint Candidates:\n",
      "1. Path: /createdb, Method: GET\n",
      "2. Path: /, Method: GET\n",
      "3. Path: /users/v1, Method: GET\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# File paths\n",
    "# base_path = \"/m2-data/jupyterNotebooks/api/test_runs/vampi-1/\"\n",
    "parsed_spec_path = f\"{output_folder}parsed_spec.json\"\n",
    "health_endpoints_path = f\"{output_folder}endpoints_health.json\"\n",
    "model_url = \"http://localhost:11434/api/generate\"  # Ollama API endpoint\n",
    "# model_name = \"qwen2.5-coder:7b\"\n",
    "\n",
    "def find_candidate_endpoints(parsed_spec):\n",
    "    \"\"\"\n",
    "    Identify candidate heartbeat endpoints based on the criteria.\n",
    "\n",
    "    Args:\n",
    "        parsed_spec (dict): The parsed OpenAPI spec JSON content.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of candidate endpoints with 200 OK responses and no parameters.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    endpoints = parsed_spec.get(\"endpoints\", [])\n",
    "    \n",
    "    for endpoint in endpoints:\n",
    "        # Check for 200 OK response\n",
    "        responses = endpoint.get(\"responses\", {})\n",
    "        if \"200\" in responses:\n",
    "            # Check for no parameters or requestBody\n",
    "            if not endpoint.get(\"parameters\") and not endpoint.get(\"requestBody\"):\n",
    "                candidates.append(endpoint)\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def query_model_for_ranking(candidates, model_name=\"qwen2.5-coder:7b\"):\n",
    "    \"\"\"\n",
    "    Query the model to rank or refine candidate heartbeat endpoints.\n",
    "\n",
    "    Args:\n",
    "        candidates (list): A list of candidate endpoints.\n",
    "        model_name (str): The name of the model to query.\n",
    "\n",
    "    Returns:\n",
    "        list: Ranked or refined list of heartbeat endpoints.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are analyzing API endpoints. Based on the following candidates, rank the endpoints \"\n",
    "        \"most likely to be a heartbeat endpoint, which typically returns 200 OK with no parameters. \"\n",
    "        \"Return the top 3 most probable candidates as a JSON array.\\n\\n\"\n",
    "        f\"Candidates:\\n{json.dumps(candidates, indent=2)}\\n\\n\"\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Stream the response for incremental output\n",
    "        response = requests.post(model_url, json=payload, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Process the streamed response incrementally\n",
    "        result = \"\"\n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                try:\n",
    "                    # Decode each line and append to result\n",
    "                    result += chunk.decode('utf-8')\n",
    "                except Exception as decode_error:\n",
    "                    print(f\"Error decoding chunk: {decode_error}\")\n",
    "\n",
    "        # Attempt to extract JSON from the response\n",
    "        try:\n",
    "            # Locate and parse the JSON part of the response\n",
    "            start_idx = result.find(\"[\")  # Assuming JSON array starts with [\n",
    "            end_idx = result.rfind(\"]\") + 1  # Assuming JSON array ends with ]\n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                ranked_candidates = json.loads(result[start_idx:end_idx])\n",
    "            else:\n",
    "                raise ValueError(\"Could not locate JSON array in model response.\")\n",
    "            return ranked_candidates\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            return candidates[:3]  # Fallback to the first 3 candidates\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying model: {e}\")\n",
    "        return candidates[:3]  # Fallback to the first 3 candidates\n",
    "\n",
    "def save_health_endpoints(health_endpoints, file_path):\n",
    "    \"\"\"\n",
    "    Save the selected health endpoints to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        health_endpoints (list): The list of health endpoints.\n",
    "        file_path (str): Path to save the JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(health_endpoints, file, indent=4)\n",
    "        print(f\"Health endpoints saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save health endpoints: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to find, rank, and save heartbeat endpoint candidates.\n",
    "    \"\"\"\n",
    "    # Load the parsed OpenAPI spec JSON file\n",
    "    try:\n",
    "        with open(parsed_spec_path, \"r\") as file:\n",
    "            parsed_spec = json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load parsed spec: {e}\")\n",
    "        return\n",
    "\n",
    "    # Find candidate endpoints\n",
    "    candidates = find_candidate_endpoints(parsed_spec)\n",
    "\n",
    "    if not candidates:\n",
    "        print(\"No candidate heartbeat endpoints found.\")\n",
    "        return\n",
    "\n",
    "    # Query the model for refined ranking\n",
    "    ranked_candidates = query_model_for_ranking(candidates)\n",
    "\n",
    "    # Save the top 3 candidates to a new JSON file\n",
    "    save_health_endpoints(ranked_candidates[:3], health_endpoints_path)\n",
    "\n",
    "    # Print the top 3 candidates\n",
    "    print(\"Top 3 Heartbeat Endpoint Candidates:\")\n",
    "    for i, candidate in enumerate(ranked_candidates[:3], start=1):\n",
    "        print(f\"{i}. Path: {candidate.get('path')}, Method: {candidate.get('method')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5276f-6696-420d-a9d9-aa5a1f81dd89",
   "metadata": {},
   "source": [
    "## Test Health Check Endpoints\n",
    "  - Appends endpoints_health.json with a list of the endpoints that were up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b880d75-15b0-493a-8e87-abde6b9077ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up endpoints successfully appended to: /m2-data/jupyterNotebooks/api/test_runs/vampi-20241231/endpoints_health.json\n",
      "Health Check Results:\n",
      "/createdb: Unexpected status code: 500\n",
      "/: Application is UP\n",
      "/users/v1: Application is UP\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1d0d749-d752-456e-b7c4-e0b1a38e1fbe",
   "metadata": {},
   "source": [
    "## Determine User Registration Endpoints\n",
    "Determine API endpoints for user registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "361bd197-bf44-48ae-8423-0bddc47ddb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted endpoints: ['/createdb', '/', '/users/v1', '/users/v1/_debug', '/users/v1/register', '/users/v1/login', '/me', '/users/v1/{username}', '/users/v1/{username}', '/users/v1/{username}/email', '/users/v1/{username}/password', '/books/v1', '/books/v1', '/books/v1/{book_title}']\n",
      "Payload being sent to LLM: {\n",
      "    \"model\": \"qwen2.5-coder:7b\",\n",
      "    \"prompt\": \"Analyze the following list of API endpoints and identify any that are related to user or account registration. Provide any relevant observations and reasoning.\\n\\nEndpoints:\\n/createdb\\n/\\n/users/v1\\n/users/v1/_debug\\n/users/v1/register\\n/users/v1/login\\n/me\\n/users/v1/{username}\\n/users/v1/{username}\\n/users/v1/{username}/email\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 98\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo registration-related endpoints identified by LLM.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 90\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted endpoints:\u001b[39m\u001b[38;5;124m\"\u001b[39m, endpoints)\n\u001b[0;32m---> 90\u001b[0m suggestions \u001b[38;5;241m=\u001b[39m \u001b[43mquery_llm_for_registration_endpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suggestions:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM-suggested registration-related endpoints:\u001b[39m\u001b[38;5;124m\"\u001b[39m, suggestions)\n",
      "Cell \u001b[0;32mIn[35], line 57\u001b[0m, in \u001b[0;36mquery_llm_for_registration_endpoints\u001b[0;34m(endpoints)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload being sent to LLM:\u001b[39m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(payload, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     59\u001b[0m     suggestions \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/m2-data/pythonEnvironments/gpu_enabled/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/m2-data/pythonEnvironments/gpu_enabled/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/m2-data/pythonEnvironments/gpu_enabled/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/m2-data/pythonEnvironments/gpu_enabled/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/m2-data/pythonEnvironments/gpu_enabled/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/m2-data/pythonEnvironments/gpu_enabled/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/m2-data/pythonEnvironments/gpu_enabled/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/m2-data/pythonEnvironments/gpu_enabled/lib/python3.11/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1390\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1390\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1392\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def extract_endpoints_from_parsed_spec(parsed_spec_path):\n",
    "    \"\"\"\n",
    "    Extract a list of endpoints from the parsed OpenAPI spec.\n",
    "\n",
    "    Args:\n",
    "        parsed_spec_path (str): Path to the parsed OpenAPI spec file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of endpoint paths.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(parsed_spec_path, \"r\") as file:\n",
    "            parsed_spec = json.load(file)\n",
    "            # Adjust to handle \"path\" as a key\n",
    "            paths = [entry[\"path\"] for entry in parsed_spec.get(\"endpoints\", []) if \"path\" in entry]\n",
    "            return paths\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or parsing the spec file: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def query_llm_for_registration_endpoints(endpoints):\n",
    "    \"\"\"\n",
    "    Query the LLM to identify registration-related endpoints.\n",
    "\n",
    "    Args:\n",
    "        endpoints (list): A list of endpoint paths.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of LLM-suggested registration-related endpoints.\n",
    "    \"\"\"\n",
    "    llm_url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "    # Limit the number of endpoints to avoid overloading the LLM\n",
    "    max_endpoints = 10\n",
    "    truncated_endpoints = endpoints[:max_endpoints]\n",
    "\n",
    "    # Construct the prompt\n",
    "    prompt = (\n",
    "        \"Analyze the following list of API endpoints and identify any that are related to \"\n",
    "        \"user or account registration. Provide any relevant observations and reasoning.\\n\\n\"\n",
    "        \"Endpoints:\\n\" + \"\\n\".join(truncated_endpoints)\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    # Debugging: Print the payload being sent\n",
    "    print(\"Payload being sent to LLM:\", json.dumps(payload, indent=4))\n",
    "\n",
    "    try:\n",
    "        response = requests.post(llm_url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        suggestions = response.json()\n",
    "        return suggestions\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"HTTP error querying LLM: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding LLM response: {e}\")\n",
    "    return []\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = requests.post(llm_url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        suggestions = response.json()\n",
    "        return suggestions\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM for registration-related endpoints: {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to extract endpoints and query LLM.\n",
    "    \"\"\"\n",
    "    parsed_spec_path = f\"{output_folder}parsed_spec.json\"\n",
    "    endpoints = extract_endpoints_from_parsed_spec(parsed_spec_path)\n",
    "\n",
    "    if not endpoints:\n",
    "        print(\"No endpoints found in the parsed spec.\")\n",
    "        return\n",
    "\n",
    "    print(\"Extracted endpoints:\", endpoints)\n",
    "\n",
    "    suggestions = query_llm_for_registration_endpoints(endpoints)\n",
    "\n",
    "    if suggestions:\n",
    "        print(\"LLM-suggested registration-related endpoints:\", suggestions)\n",
    "    else:\n",
    "        print(\"No registration-related endpoints identified by LLM.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa2aa4b-e86f-4cc6-9ad1-c622a244b174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU",
   "language": "python",
   "name": "gpu_enabled"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
